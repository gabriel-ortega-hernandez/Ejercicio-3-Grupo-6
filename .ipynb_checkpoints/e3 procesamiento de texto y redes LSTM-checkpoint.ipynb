{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-YiltMLCEeT"
   },
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**20/07/2020 - E3 S15**\n",
    "\n",
    "\n",
    "**Integrantes del grupo**:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zejcg_ArCEeW"
   },
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unIMQSF-CEeZ"
   },
   "source": [
    "El objetivo de esta evaluación es resolver un problema de detección de noticias falsas (*Fake News*) usando herramientas de aprendizaje de máquinas. \n",
    "\n",
    "Para lograr una representación numérica de los textos utilizaremos la librería `spaCy` para procesamiento de lenguaje natural. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFE7fvkSCEeb"
   },
   "source": [
    "**Instalaciones previas**  \n",
    "Para la ejecución correcta de este notebook puede ser necesario ejecutar los siguientes comandos de instalación:\n",
    "\n",
    "```python\n",
    "!pip install spacy tqdm\n",
    "!pip install -c pytorch torchtext\n",
    "!python -m spacy download en_core_web_sm\n",
    "```\n",
    "**Obs:** Puede usar conda en vez de pip si maneja su librería con esta herramienta. \n",
    "\n",
    "Las librerías que se instalan son:\n",
    "- spacy: ampliamente usada para procesamiento de lenguaje natural. Esta librería posee modelos estadísticos preentrenados como `en_core_web_sm` que será detallado posteriormente.\n",
    "- tqdm: para mostrar barras de progreso en pantalla.\n",
    "- torchtext: contiene en herramientas populares de procesamiento de lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kixIAB7CEed"
   },
   "source": [
    "**Librerías**  \n",
    "En la evaluación, **no** estará permitido usar librerías ni módulos diferentes a los declarados en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "9mDw369JCEef",
    "outputId": "c5619391-cbc8-46d5-8362-06b9ac542056"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report,\\\n",
    "    confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "'''\n",
    "Puede utilizar esta extension si trabaja en colaboratory:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rA4Rg0XfCEeq"
   },
   "source": [
    "**Replicabilidad**  \n",
    "A lo largo de todo el ejercicio llamaremos múltiples veces a la función `np.random.seed`, con la semilla fija en la variable `seed_=300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5gBzo2SCEes"
   },
   "outputs": [],
   "source": [
    "seed_ = 300\n",
    "np.random.seed(seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ML4pIcNTjIy"
   },
   "source": [
    "**Uso de GPU**  \n",
    "En este ejercicio se utilizarán modelos que requieren alto poder de computo por lo que se recomienda usar GPU. Recuerde que en **Colaboratory** tiene acceso gratuito a dicho recurso.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVVP3vtvUFSY"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wc0YidsCEez"
   },
   "source": [
    "## Preliminares\n",
    "\n",
    "### Carga de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTqNQrWP34mq"
   },
   "source": [
    "- Compruebe que la siguiente celda coincide con este output:\n",
    "\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "Int64Index: 6335 entries, 8476 to 4330\n",
    "Data columns (total 3 columns):\n",
    " #   Column  Non-Null Count  Dtype \n",
    "---  ------  --------------  ----- \n",
    " 0   title   6335 non-null   object\n",
    " 1   text    6335 non-null   object\n",
    " 2   label   6335 non-null   object\n",
    "dtypes: object(3)\n",
    "memory usage: 198.0+ KB\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "FpKqWXBvCEe0",
    "outputId": "28cb3b55-5f87-4dcf-98f6-12ff70ef0f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6335 entries, 8476 to 4330\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   6335 non-null   object\n",
      " 1   text    6335 non-null   object\n",
      " 2   label   6335 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 198.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# cargar con internet\n",
    "#  raw_data_path = 'https://raw.githubusercontent.com/NicoCaro/DataScienceLab/master/ejercicios/ejercicio%203/data/news.csv'\n",
    "# raw_df = pd.read_csv(raw_data_path, index_col=0)\n",
    "## cargar sin internet\n",
    "raw_df = pd.read_csv('.\\\\data\\\\news.csv', index_col=0)\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHVO5t1KCEe7"
   },
   "source": [
    "**Preprocesamiento**  \n",
    "El conjunto de datos consta de 3 columnas:\n",
    "- `title`: contiene el título de la noticia\n",
    "- `text`: contiene el teto de la noticia\n",
    "- `label`: contiene las etiquetas `REAL` y `FAKE` que indican si se trata de una noticia verdadera o falsa.\n",
    "\n",
    "En la siguiente celda se incluye la columna `X` con una concatenación del título y el texto de las noticias, además de la columna `y` como una representación numérica de la columna `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "XrFTxJiwCEe8",
    "outputId": "f6a23316-224f-4ad9-ea23-f6479aec9c31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear. Daniel Greenfiel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy. U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       X  y\n",
       "8476   You Can Smell Hillary’s Fear. Daniel Greenfiel...  1\n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...  1\n",
       "3608   Kerry to go to Paris in gesture of sympathy. U...  0\n",
       "10142  Bernie supporters on Twitter erupt in anger ag...  1\n",
       "875    The Battle of New York: Why This Primary Matte...  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pro_df = raw_df.copy()\n",
    "pro_df['y'] = (pro_df['label'] == 'FAKE').astype('int')\n",
    "pro_df['X'] = pro_df['title'].str.cat(pro_df['text'], sep='. ')\n",
    "\n",
    "# se eliminan las columnas innecesarias\n",
    "pro_df = pro_df.reindex(columns=['X', 'y'])\n",
    "display(pro_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dX2EcoxICEfC"
   },
   "source": [
    "### Procesamiento de texto\n",
    "A modo de ejemplo se muestra el procesamiento que se busca aplicar a cada una de las observaciones de la columna `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "-RUH-Z0KCEfE",
    "outputId": "4ee0ce42-bdfd-44d8-a522-d6f18a4acdd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noticia falsa\n",
      "------------------------------------------------------------------------\n",
      "Bernie supporters on Twitter erupt in anger against the DNC: 'We tried to warn you!'. — Kaydee King (@KaydeeKing) November 9, 2016 The lesson from tonight's Dem losses: Time for Democrats to start listening to the voters. Stop running the same establishment candidates. \r\n",
      "— People For Bernie (@People4Bernie) November 9, 2016 If Dems didn't want a tight race they shouldn't have worked against Bernie. \r\n",
      "— Walker Bragman (@WalkerBragman) November 9, 2016 \r\n",
      "New York Times columnist Paul Krugman, who w ...\n"
     ]
    }
   ],
   "source": [
    "x_muestra, y_muestra = pro_df.iloc[3].values.T\n",
    "print('Noticia falsa' if y_muestra else 'Noticia verdadera', '-' * 72,  sep='\\n')\n",
    "print(x_muestra[:501], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jgLJ3uE1CEfJ"
   },
   "source": [
    "**Definición del modelo `spacy`**  \n",
    "El modelo estadístico de `spacy` que usaremos en el ejercicio es `english_web_sm`, que consiste en un objeto basado en una red convolucional, preentrenada en un conjunto de datos llamado Ontowords y diseñada para resolver múltiples tareas de procesamiento de lenguaje natural, dento de sus métodos se encuentran rutinas de tokenización y lematización detalladas posteriormente.\n",
    "\n",
    "Dentro de las funcionalidades que entrega este modelo, hay un subconjunto que no se utilizará en el ejercicio. Para ahorrar tiempo de cómputo, estas funcionalidades son deshabilitadas en el  el argumento `disable`.\n",
    "\n",
    "**Obs:** Puede ser necesario ejecutar `python -m spacy download en_core_web_sm` para tener acceso a tal modelo de lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DhOaF6SDCEfK",
    "outputId": "bdc4e6cc-5c21-462c-b6d0-63fef2d321fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lang.en.English'>\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['entitry_ruler', 'textcat', \n",
    "                                            'entity_linker', 'ner', 'tagger'])\n",
    "print(type(nlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUcaWEY4CEfP"
   },
   "source": [
    "**Tokenización**  \n",
    "\n",
    "Lo primero para analizar texto es separar el campo de texto en _tokens_. Un _token_ es un segmento significativo del texto. La entrada al tokenizer es un texto unicode, y la salida es un `spacy.tokens.doc.Doc`.\n",
    "\n",
    "\n",
    "El proceso puede entenderse como:\n",
    "1. Aplicar el método `str.split(' ')` que entrega una lista de `str`.\n",
    "2. Verificar si cada uno de los elementos de la lista puede subdividirse:\n",
    "    1. **Porque se trata de una regla de excepción.** Por ejemplo `don't` debería subdividirse en `do` y `n't`, mientras que `U.K.` no debe subdividirse.\n",
    "    2. **Porque el elemento contiene prefijos, sufijos o [infijos](https://dle.rae.es/infijo).** Por ejemplo comillas, comas, puntos, etc...\n",
    "    \n",
    "Para más detalles ver la documentación de [spacy](https://spacy.io/usage/linguistic-features#tokenization).\n",
    "\n",
    "Así al generar *tokens* en `x_muestra`, los 20 primeros son: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "JRloFA6CCEfP",
    "outputId": "994a1463-d213-43b1-d17e-3353e8594efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernie\n",
      "supporters\n",
      "on\n",
      "Twitter\n",
      "erupt\n",
      "in\n",
      "anger\n",
      "against\n",
      "the\n",
      "DNC\n",
      ":\n",
      "'\n",
      "We\n",
      "tried\n",
      "to\n",
      "warn\n",
      "you\n",
      "!\n",
      "'\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "spacy_doc = nlp(x_muestra)\n",
    "[print(token) for token in spacy_doc[:20]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oB5xDaiXCEfW"
   },
   "source": [
    "**Lematización**  \n",
    "La [lematización](https://es.wikipedia.org/wiki/Lematizaci%C3%B3n) es el proceso de agrupar las formas flexionadas de una palabra (en plural, en femenino, conjugada, etc), para que puedan analizarse como un solo elemento, identificado por el **lema** de la palabra.\n",
    "\n",
    "En procesamiento de lenguaje natural a lematización depende de la identificación correcta de la [categoría gramatical](https://es.wikipedia.org/wiki/Categor%C3%ADa_gramatical) (*part of speech*). Algunos ejemplos de categoría gramatical son sustantivo, adjetivo, verbo, advervio, etc...\n",
    "\n",
    "En `spacy` accedemos al lema mediante el atributo `lemma_`. Así, para los 20 primeros *tokens*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "AKskjZS8CEfW",
    "outputId": "61fe3790-ee8e-45d0-aa2a-abc4559dd68e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernie\n",
      "supporter\n",
      "on\n",
      "Twitter\n",
      "erupt\n",
      "in\n",
      "anger\n",
      "against\n",
      "the\n",
      "DNC\n",
      ":\n",
      "'\n",
      "We\n",
      "try\n",
      "to\n",
      "warn\n",
      "you\n",
      "!\n",
      "'\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "[print(token.lemma_) for token in spacy_doc[:20]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T0jrekzgCEfb"
   },
   "source": [
    "**Stopwords**  \n",
    "Los *tokens* generados pueden ser clasificados como [palabras vacías](https://es.wikipedia.org/wiki/Palabra_vac%C3%ADa) (*stop words*) que no tienen significado en si mismas. Algunos ejemplos son preposiciones, artículos, pronombres, etc... En procesamiento de lenguaje natural es común eliminarlas.\n",
    "\n",
    "Para este ejercicio eliminaremos las *palabras vacías* mediante el atributo `is_stop`, además de los *token* que no sean alfanuméricos mediante el atributo `is_alpha`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "HuBvA32OCEfc",
    "outputId": "63535eca-ebfb-4074-a31c-185546e4bcc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernie\n",
      "supporters\n",
      "Twitter\n",
      "erupt\n",
      "anger\n",
      "DNC\n",
      "tried\n",
      "warn\n"
     ]
    }
   ],
   "source": [
    "[print(token) for token in spacy_doc[:20] if (not token.is_stop) and token.is_alpha];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3x2F0cVCEfi"
   },
   "source": [
    "#### Pregunta 1\n",
    "1. Defina la función `procesa_texto` que reciba como argumento un texto y un modelo de lenguaje `spacy`. La función `procesa_texto` debe entregar un texto con los lemas de cada *token*, eliminando las palabras vacías y los *token* que no sean alfanuméricos, usando el procedimiento recién presentado. El texto obtenido debe separar los lemas por espacios `' '`.\n",
    "2. Aplique dicha función a la columna `X`, guardando sus resultados en la columna `pro_X`. Como modelo de lenguaje `spacy`, utilice el modelo instanciado anteriormente.  \n",
    "    **Observaciones**:\n",
    "    - Es usual que esta operación tome bastante tiempo por lo que recomendamos usar el método `progress_apply` de pandas que permite reportar el progreso de la operación mediante la librería `tqdm`. Para habilitar dicho método de la librería pandas debe primero llamar al método `tqdm.pandas`.\n",
    "    - Puede ser útil guardar el resultado de esta operación en disco, dado el tiempo que toma repetir la operación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4b27412f255843bb9560597505968c6e",
      "4ba4377c4d084df0bcf7b4b589e04746",
      "dc85519c59374446b63168fd61028183",
      "ea81a5d515b64fda92d82e0ecff58d48",
      "0ab4e52784094972a9a2eaac29459c58",
      "078b2fa807ec46e58d906a68b9276e33",
      "7241d9cf4ba349198cba3b5c90bd47ff",
      "f8980260172a4afc85dd63e65309e820"
     ]
    },
    "colab_type": "code",
    "id": "EWXqJHA3CEfj",
    "outputId": "98a62c27-5b2b-44cc-c27c-5e3c2c5f369a"
   },
   "outputs": [],
   "source": [
    "def procesa_texto(texto, modelo=nlp):\n",
    "    ''' Funcion que procesa texto eliminando palabras vacias y que no son alfanumericas'''\n",
    "    tokens = [token for token in modelo(texto) if (not token.is_stop) and token.is_alpha]\n",
    "    lemas = [token.lemma_ for token in tokens]\n",
    "    return ' '.join(lemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bernie supporter Twitter erupt anger DNC try warn Kaydee King November lesson tonight Dem loss Time Democrats start listen voter Stop run establishment candidate People Bernie November Dems want tight race work Bernie Walker Bragman November New York Times columnist Paul Krugman Hillary Clinton outspoken surrogate contentious Democratic primary blame Clinton poor performance Green Party candidate Jill Stein far receive negligible numb vote nationally say Stein Ralph Nader prevent Clinton victory account throw Krugman analysis face candidate issue responsibility Teachers Bernie November Ana Navarro Republican recently endorse Hillary Clinton sum preposterous nature presidential election tweet GOP nominate damn candidate lose Hillary Clinton Democrats nominate damn candidate lose Trump Ana Navarro November Popular leave wing Facebook page pro Sanders primary respond Trump surge simply post meme Sanders face text avoid Thanks DNC meme share time hour Posted Tuesday November Bernie Sanders endorse Hillary Clinton Democratic National Convention July supporter remain adamant refusal support DNC anoint candidate point WikiLeaks revelation official DNC work scene tip scale Clinton favor coordinate medium figure circulate anti Sanders narrative attribute potential Trump presidency GOP nominee perceive popularity voter closeness election credit Hillary Clinton unfavorable rating According RealClearPolitics percent voter negative opinion Democratic nominee PM Eastern Florida Michigan Pennsylvania Wisconsin remain close Clinton electoral vote Trump Zach Cartwright activist author Richmond Virginia enjoy write politic government medium Send email email protect'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se prueba la función\n",
    "procesa_texto(x_muestra, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f1f15323634503b6cca08918f494ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6335.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Se agrega columna procesada al DataFrame\n",
    "tqdm.pandas()\n",
    "pro_df['pro_X'] = pro_df['X'].progress_apply(procesa_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_QePI5bCEfq"
   },
   "source": [
    "3. Cuente el número de lemas en cada observación de la columna `pro_X` y compruebe que obtiene las siguientes estadísticas descriptivas:\n",
    "\n",
    "```\n",
    "count    6335.000000\n",
    "mean      393.084294\n",
    "std       409.950812\n",
    "min         2.000000\n",
    "25%       153.000000\n",
    "50%       311.000000\n",
    "75%       515.000000\n",
    "max      8730.000000\n",
    "Name: pro_X, dtype: float64\n",
    "```\n",
    "*Hint*: puede ser útil el método `pd.Series.str.count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWGdXsbPD4ow"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6335.000000\n",
       "mean      393.069298\n",
       "std       409.934015\n",
       "min         2.000000\n",
       "25%       153.000000\n",
       "50%       311.000000\n",
       "75%       515.000000\n",
       "max      8729.000000\n",
       "Name: pro_X, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_df['pro_X'].str.split().str.len().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_nsPKTtCEfv"
   },
   "source": [
    "4. Instancie `final_df` como una copia de `pro_df` a la que se le elimina la columna `'X'`. Luego aplique la eliminación de los duplicados `final_df`.   \n",
    "- Compruebe que obtiene un total de 6,303 filas únicas en `final_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_88ZW5V4D-7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6303"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pro_df[['pro_X', 'y']].copy()\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "final_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda DataFrame para ahorrar tiempo\n",
    "final_df.to_pickle(\"data/final_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga DataFrame\n",
    "final_df = pd.read_pickle(\"data/final_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>Smell Hillary Fear Daniel Greenfield Shillman ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch Exact Moment Paul Ryan Committed Politic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry Paris gesture sympathy Secretary State J...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporter Twitter erupt anger DNC try w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Battle New York Primary Matters primary day Ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>State Department say find email Clinton specia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>P PBS Stand Plutocratic Pentagon P PBS Stand P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8622</th>\n",
       "      <td>Anti Trump Protesters Tools Oligarchy Informat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>Ethiopia Obama seek progress peace security Ea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>Jeb Bush Suddenly Attacking Trump Matters Jeb ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6303 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pro_X  y\n",
       "8476   Smell Hillary Fear Daniel Greenfield Shillman ...  1\n",
       "10294  Watch Exact Moment Paul Ryan Committed Politic...  1\n",
       "3608   Kerry Paris gesture sympathy Secretary State J...  0\n",
       "10142  Bernie supporter Twitter erupt anger DNC try w...  1\n",
       "875    Battle New York Primary Matters primary day Ne...  0\n",
       "...                                                  ... ..\n",
       "4490   State Department say find email Clinton specia...  0\n",
       "8062   P PBS Stand Plutocratic Pentagon P PBS Stand P...  1\n",
       "8622   Anti Trump Protesters Tools Oligarchy Informat...  1\n",
       "4021   Ethiopia Obama seek progress peace security Ea...  0\n",
       "4330   Jeb Bush Suddenly Attacking Trump Matters Jeb ...  0\n",
       "\n",
       "[6303 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbojUolFCEf2"
   },
   "source": [
    "### Definición de notación\n",
    "De ahora en adelante denotamos por:\n",
    "- ***Documento***: cada una de las noticias procesadas del conjunto de datos, es decir, cada una de las observaciones de la columna `'pro_X'`del DataFrame `final_df`.\n",
    "- ***Corpus***: el conjunto de *documentos* del conjunto de datos, es decir, el conjunto de observaciones de la columna `'pro_X'` del DataFrame `final_df`.\n",
    "- ***Vocabulario***: al conjunto de *tokens* presentes en el *corpus*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySZAaNLlCEf3"
   },
   "source": [
    "### Definición de conjuntos del problema\n",
    "Se separan las muestras en dos conjuntos:\n",
    "- Conjunto de *entrenamiento union validación* (denotado por `*_full_train`), con el 80% de las observaciones\n",
    "- Conjunto de *prueba* (denotado por `*_test`), con el 20% de las observaciones.\n",
    "\n",
    "A su vez el conjunto de *entrenamiento union validación* de subdivide en:\n",
    "- Conjunto de *entrenamiento* (denotado por `*_train`), con el 64% de las observaciones.\n",
    "- Conjunto de *validación* (denotado por `*_val`), con el 16% de las observaciones\n",
    "\n",
    "Para realizar esta subdivisión utilizamos dos veces la función `sklearn.model_selection.train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YYSQ9p4CEf7"
   },
   "outputs": [],
   "source": [
    "# define parametros de la division de conjuntos\n",
    "proporcion_total_entrenamiento_prueba = 0.80\n",
    "proporcion_entrenamiento_validacion = 0.80\n",
    "\n",
    "# obtiene conjunto de prueba\n",
    "X_full_train, X_test, y_full_train, y_test= train_test_split(\n",
    "    final_df.pro_X, final_df.y, train_size=proporcion_total_entrenamiento_prueba, \n",
    "    random_state=seed_)\n",
    "\n",
    "# obtiene conjunto de entrnamiento y validacion\n",
    "X_train, X_val, y_train, y_val  = train_test_split(\n",
    "    X_full_train, y_full_train, train_size=proporcion_entrenamiento_validacion, \n",
    "    random_state=seed_)\n",
    "\n",
    "# guardar los conjuntos en formato csv\n",
    "conjuntos_dir = 'conjuntos'\n",
    "os.makedirs(conjuntos_dir, exist_ok=True)\n",
    "guarda_csv = lambda X, y, filename: pd.DataFrame({\n",
    "    'pro_X': X, 'y': y\n",
    "}).to_csv(f'{conjuntos_dir}/{filename}.csv', index=None)\n",
    "guarda_csv(X_train, y_train, 'entrenamiento')\n",
    "guarda_csv(X_val, y_val, 'validacion')\n",
    "guarda_csv(X_test, y_test, 'prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar archivos de la carpeta 'conjuntos'\n",
    "X_train, y_train = (pd.read_csv('.\\\\conjuntos\\\\entrenamiento.csv')['pro_X'], \n",
    "                    pd.read_csv('.\\\\conjuntos\\\\entrenamiento.csv')['y'])\n",
    "X_val, y_val = (pd.read_csv('.\\\\conjuntos\\\\validacion.csv')['pro_X'], \n",
    "                    pd.read_csv('.\\\\conjuntos\\\\validacion.csv')['y'])\n",
    "X_test, y_test = (pd.read_csv('.\\\\conjuntos\\\\prueba.csv')['pro_X'], \n",
    "                    pd.read_csv('.\\\\conjuntos\\\\prueba.csv')['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yDRxP4ebCEf_"
   },
   "source": [
    "## Modelos de aprendizaje de máquinas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAg8An6BEsDg"
   },
   "source": [
    "### Modelos no paramétricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kljsRVFCEgA"
   },
   "source": [
    "#### Representación por conteo de ocurrencias.\n",
    "Dado que se busca resolver un problema de clasificación de documentos, es necesario representar los documentos de forma numérica. A continuación usaremos la representación por conteo de apariciones de cada uno de los *tokens* presentes en el *vocabulario*.\n",
    "\n",
    "Para realizar esta vectorización de documentos se utiliza la clase `sklearn.feature_extraction.text.CountVectorizer`. El método `fit_transform` de esta clase  recibe como argumento un `iterable` de *documentos*, extrae el *vocabulario* de dicho `iterable` y retorna la matriz de número de ocurrencias de cada *token* del *vocabulario*, en cada uno de los documentos del `iterable`. En otras palabras, definiendo $\\text{tf}(t_i, \\mathbf{d}_j)$ como el número de apariciones del *token* $t_i$ en el *documento* $\\mathbf{d}_j$, `~CountVectorizer.fit_transform` retorna la matriz $\\mathbf{C}$ definida por:\n",
    "$$\\big(c_{i, j}\\big) = \\text{tf}(t_j, \\mathbf{d}_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14YOBySYCEgB"
   },
   "source": [
    "#### Naive Bayes\n",
    "\n",
    "Se emplea el algoritmo de *Naive Bayes* como base de referencia para los modelos más complejos empleados posteriormente. Específicamente, se utiliza una instancia de la clase `sklearn.naive_bayes.MultinomialNB` que está diseñado para trabajar con las características del tipo conteo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LXS7kANE0A-"
   },
   "source": [
    "##### Pregunta 2\n",
    "1. Instancie `nb_pipe` como un objeto de la clase `sklearn.pipeline.Pipeline` con los componentes:\n",
    "    - `~CountVectorizer` inicializado con `max_features=20000` los demás parámetros por defecto.\n",
    "    - `~MultinomialNB` inicializado con los parámetros por defecto.  \n",
    "    \n",
    "   Posteriormente, ajuste `nb_pipe` en el conjunto de *entrenamiento union validación* y guarde el modelo resultante en la carpeta `modelos/nb_pipe.pk` como un archivo `pickle`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBiY5mcwEC1N"
   },
   "outputs": [],
   "source": [
    "# instanciar nb_pipe\n",
    "nb_pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "\n",
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "trans = count.fit_transform(raw_documents = X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'content',\n",
       " 'encoding': 'utf-8',\n",
       " 'decode_error': 'strict',\n",
       " 'strip_accents': None,\n",
       " 'preprocessor': None,\n",
       " 'tokenizer': None,\n",
       " 'analyzer': 'word',\n",
       " 'lowercase': True,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'stop_words': None,\n",
       " 'max_df': 1.0,\n",
       " 'min_df': 1,\n",
       " 'max_features': None,\n",
       " 'ngram_range': (1, 1),\n",
       " 'vocabulary': None,\n",
       " 'binary': False,\n",
       " 'dtype': numpy.int64,\n",
       " 'fixed_vocabulary_': False,\n",
       " '_stop_words_id': 140710650535136,\n",
       " 'stop_words_': set(),\n",
       " 'vocabulary_': {'gay': 15275,\n",
       "  'marriage': 23696,\n",
       "  'victory': 41462,\n",
       "  'supreme': 37557,\n",
       "  'court': 8491,\n",
       "  'trigger': 39488,\n",
       "  'backlash': 2935,\n",
       "  'corrections': 8316,\n",
       "  'clarification': 6936,\n",
       "  'early': 11644,\n",
       "  'version': 41383,\n",
       "  'story': 36978,\n",
       "  'misidentify': 24897,\n",
       "  'alabama': 953,\n",
       "  'official': 27220,\n",
       "  'lead': 22009,\n",
       "  'effort': 11847,\n",
       "  'sex': 34751,\n",
       "  'state': 36683,\n",
       "  'chief': 6597,\n",
       "  'justice': 20617,\n",
       "  'washington': 42013,\n",
       "  'declare': 9520,\n",
       "  'constitutional': 7967,\n",
       "  'right': 32869,\n",
       "  'june': 20589,\n",
       "  'man': 23427,\n",
       "  'win': 42540,\n",
       "  'case': 5933,\n",
       "  'warn': 41975,\n",
       "  'opponent': 27473,\n",
       "  'find': 14028,\n",
       "  'new': 26317,\n",
       "  'way': 42080,\n",
       "  'push': 30918,\n",
       "  'continue': 8067,\n",
       "  'fight': 13951,\n",
       "  'jim': 20349,\n",
       "  'obergefell': 27026,\n",
       "  'say': 33971,\n",
       "  'nearly': 26127,\n",
       "  'year': 43060,\n",
       "  'seesaw': 34472,\n",
       "  'battle': 3416,\n",
       "  'religious': 32198,\n",
       "  'exemption': 13064,\n",
       "  'transgender': 39312,\n",
       "  'replace': 32347,\n",
       "  'movement': 25491,\n",
       "  'steady': 36747,\n",
       "  'progress': 30459,\n",
       "  'protection': 30615,\n",
       "  'discrimination': 10623,\n",
       "  'city': 6877,\n",
       "  'legislative': 22134,\n",
       "  'legal': 22111,\n",
       "  'skirmish': 35581,\n",
       "  'intransigent': 19640,\n",
       "  'defiant': 9642,\n",
       "  'kentucky': 20974,\n",
       "  'county': 8474,\n",
       "  'clerk': 7016,\n",
       "  'colorado': 7380,\n",
       "  'baker': 3054,\n",
       "  'florist': 14316,\n",
       "  'recently': 31724,\n",
       "  'conservative': 7911,\n",
       "  'travel': 39372,\n",
       "  'east': 11675,\n",
       "  'texas': 38520,\n",
       "  'mississippi': 24945,\n",
       "  'north': 26741,\n",
       "  'carolina': 5864,\n",
       "  'think': 38671,\n",
       "  'kristen': 21498,\n",
       "  'waggoner': 41827,\n",
       "  'senior': 34592,\n",
       "  'vice': 41438,\n",
       "  'president': 30172,\n",
       "  'advocacy': 646,\n",
       "  'alliance': 1124,\n",
       "  'defending': 9628,\n",
       "  'freedom': 14746,\n",
       "  'represent': 32381,\n",
       "  'bathroom': 3400,\n",
       "  'law': 21947,\n",
       "  'deny': 9950,\n",
       "  'people': 28753,\n",
       "  'use': 40995,\n",
       "  'public': 30772,\n",
       "  'restroom': 32575,\n",
       "  'correspond': 8326,\n",
       "  'gender': 15336,\n",
       "  'identity': 18416,\n",
       "  'dominate': 11061,\n",
       "  'lgbt': 22326,\n",
       "  'debate': 9431,\n",
       "  'past': 28452,\n",
       "  'month': 25281,\n",
       "  'country': 8471,\n",
       "  'meet': 24196,\n",
       "  'local': 22680,\n",
       "  'opposition': 27486,\n",
       "  'expect': 13122,\n",
       "  'houston': 18043,\n",
       "  'time': 38872,\n",
       "  'elect': 11961,\n",
       "  'lesbian': 22238,\n",
       "  'mayor': 23936,\n",
       "  'force': 14461,\n",
       "  'defensive': 9634,\n",
       "  'great': 16146,\n",
       "  'success': 37298,\n",
       "  'decision': 9505,\n",
       "  'hodges': 17707,\n",
       "  'extend': 13231,\n",
       "  'nationwide': 26028,\n",
       "  'war': 41945,\n",
       "  'david': 9334,\n",
       "  'stacy': 36553,\n",
       "  'government': 15981,\n",
       "  'affair': 681,\n",
       "  'director': 10516,\n",
       "  'human': 18135,\n",
       "  'rights': 32880,\n",
       "  'campaign': 5611,\n",
       "  'nation': 26013,\n",
       "  'large': 21825,\n",
       "  'organization': 27576,\n",
       "  'intensity': 19481,\n",
       "  'emotional': 12201,\n",
       "  'come': 7433,\n",
       "  'side': 35281,\n",
       "  'individual': 19001,\n",
       "  'live': 22617,\n",
       "  'free': 14741,\n",
       "  'moral': 25318,\n",
       "  'interference': 19530,\n",
       "  'education': 11812,\n",
       "  'employment': 12233,\n",
       "  'house': 18027,\n",
       "  'long': 22772,\n",
       "  'lawsuit': 21968,\n",
       "  'head': 17101,\n",
       "  'moment': 25161,\n",
       "  'go': 15786,\n",
       "  'short': 35142,\n",
       "  'lot': 22850,\n",
       "  'damage': 9181,\n",
       "  'shannon': 34878,\n",
       "  'minter': 24804,\n",
       "  'national': 26014,\n",
       "  'center': 6195,\n",
       "  'ultimately': 39965,\n",
       "  'decide': 9492,\n",
       "  'title': 38948,\n",
       "  'vii': 41504,\n",
       "  'civil': 6884,\n",
       "  'act': 403,\n",
       "  'ix': 20017,\n",
       "  'amendments': 1298,\n",
       "  'fully': 14950,\n",
       "  'protect': 30611,\n",
       "  'matt': 23865,\n",
       "  'anthony': 1648,\n",
       "  'kennedy': 20961,\n",
       "  'historic': 17632,\n",
       "  'rule': 33398,\n",
       "  'include': 18856,\n",
       "  'single': 35446,\n",
       "  'paragraph': 28274,\n",
       "  'amendment': 1297,\n",
       "  'ensure': 12442,\n",
       "  'person': 28890,\n",
       "  'give': 15643,\n",
       "  'proper': 30543,\n",
       "  'seek': 34460,\n",
       "  'teach': 38208,\n",
       "  'principle': 30305,\n",
       "  'fulfill': 14942,\n",
       "  'central': 6203,\n",
       "  'faith': 13433,\n",
       "  'deep': 9583,\n",
       "  'aspiration': 2344,\n",
       "  'family': 13495,\n",
       "  'structure': 37118,\n",
       "  'revere': 32697,\n",
       "  'concede': 7669,\n",
       "  'true': 39601,\n",
       "  'oppose': 27481,\n",
       "  'reason': 31649,\n",
       "  'begin': 3580,\n",
       "  'merchant': 24354,\n",
       "  'refuse': 32011,\n",
       "  'participate': 28384,\n",
       "  'wedding': 42151,\n",
       "  'base': 3337,\n",
       "  'objection': 27038,\n",
       "  'target': 38100,\n",
       "  'lose': 22840,\n",
       "  'round': 33267,\n",
       "  'appeal': 1845,\n",
       "  'major': 23315,\n",
       "  'sign': 35322,\n",
       "  'resistance': 32497,\n",
       "  'high': 17504,\n",
       "  'leave': 22059,\n",
       "  'field': 13935,\n",
       "  'voters': 41745,\n",
       "  'annise': 1573,\n",
       "  'parker': 28335,\n",
       "  'openly': 27437,\n",
       "  'reject': 32142,\n",
       "  'council': 8410,\n",
       "  'pass': 28426,\n",
       "  'ordinance': 27551,\n",
       "  'resident': 32483,\n",
       "  'characteristic': 6380,\n",
       "  'sexual': 34761,\n",
       "  'orientation': 27596,\n",
       "  'simple': 35404,\n",
       "  'slogan': 35700,\n",
       "  'men': 24303,\n",
       "  'women': 42707,\n",
       "  'bathrooms': 3401,\n",
       "  'identify': 18414,\n",
       "  'open': 27433,\n",
       "  'exploit': 13182,\n",
       "  'james': 20110,\n",
       "  'esseks': 12739,\n",
       "  'american': 1308,\n",
       "  'liberties': 22359,\n",
       "  'union': 40497,\n",
       "  'legislature': 22138,\n",
       "  'south': 36164,\n",
       "  'dakota': 9156,\n",
       "  'georgia': 15425,\n",
       "  'bill': 3990,\n",
       "  'veto': 41413,\n",
       "  'republican': 32412,\n",
       "  'governor': 15984,\n",
       "  'dennis': 9923,\n",
       "  'daugaard': 9325,\n",
       "  'nathan': 26007,\n",
       "  'deal': 9402,\n",
       "  'phil': 29045,\n",
       "  'bryant': 5145,\n",
       "  'pat': 28469,\n",
       "  'mccrory': 24005,\n",
       "  'service': 34697,\n",
       "  'prevent': 30234,\n",
       "  'municipality': 25668,\n",
       "  'establish': 12751,\n",
       "  'see': 34453,\n",
       "  'explosion': 13192,\n",
       "  'liberty': 22361,\n",
       "  'legislation': 22133,\n",
       "  'wake': 41859,\n",
       "  'mat': 23818,\n",
       "  'staver': 36732,\n",
       "  'chairman': 6297,\n",
       "  'counsel': 8417,\n",
       "  'firm': 14094,\n",
       "  'tank': 38055,\n",
       "  'involve': 19742,\n",
       "  'call': 5552,\n",
       "  'tip': 38920,\n",
       "  'iceberg': 18370,\n",
       "  'settle': 34726,\n",
       "  'rest': 32553,\n",
       "  'reach': 31564,\n",
       "  'floor': 14298,\n",
       "  'representatives': 32384,\n",
       "  'intend': 19473,\n",
       "  'ban': 3135,\n",
       "  'federal': 13726,\n",
       "  'contractor': 8088,\n",
       "  'fire': 14069,\n",
       "  'worker': 42775,\n",
       "  'bisexual': 4105,\n",
       "  'measure': 24117,\n",
       "  'block': 4282,\n",
       "  'beset': 3827,\n",
       "  'conflict': 7796,\n",
       "  'advocate': 647,\n",
       "  'little': 22609,\n",
       "  'post': 29840,\n",
       "  'agendum': 768,\n",
       "  'community': 7546,\n",
       "  'accommodation': 288,\n",
       "  'utah': 41049,\n",
       "  'march': 23566,\n",
       "  'activist': 416,\n",
       "  'wall': 41890,\n",
       "  'remain': 32217,\n",
       "  'marry': 23700,\n",
       "  'sunday': 37436,\n",
       "  'work': 42769,\n",
       "  'day': 9357,\n",
       "  'travis': 39382,\n",
       "  'weber': 42142,\n",
       "  'research': 32456,\n",
       "  'need': 26147,\n",
       "  'dissenter': 10811,\n",
       "  'set': 34716,\n",
       "  'difficult': 10399,\n",
       "  'forward': 14593,\n",
       "  'response': 32543,\n",
       "  'reality': 31616,\n",
       "  'richmond': 32816,\n",
       "  'favor': 13640,\n",
       "  'boy': 4735,\n",
       "  'sue': 37325,\n",
       "  'virginia': 41570,\n",
       "  'school': 34132,\n",
       "  'district': 10864,\n",
       "  'policy': 29625,\n",
       "  'handful': 16770,\n",
       "  'york': 43146,\n",
       "  'controversial': 8129,\n",
       "  'conversion': 8153,\n",
       "  'therapy': 38620,\n",
       "  'minor': 24796,\n",
       "  'make': 23325,\n",
       "  'prospect': 30594,\n",
       "  'non': 26609,\n",
       "  'red': 31840,\n",
       "  'actually': 431,\n",
       "  'daunt': 9329,\n",
       "  'energize': 12350,\n",
       "  'loss': 22845,\n",
       "  'objector': 27044,\n",
       "  'amidst': 1333,\n",
       "  'presidential': 30174,\n",
       "  'election': 11967,\n",
       "  'divide': 10907,\n",
       "  'geographical': 15407,\n",
       "  'ideological': 18417,\n",
       "  'cultural': 8955,\n",
       "  'line': 22514,\n",
       "  'stake': 36583,\n",
       "  'big': 3953,\n",
       "  'shower': 35183,\n",
       "  'opposite': 27485,\n",
       "  'door': 11125,\n",
       "  'broadly': 5031,\n",
       "  'jeopardize': 20270,\n",
       "  'fed': 13724,\n",
       "  'holds': 17752,\n",
       "  'raising': 31320,\n",
       "  'rates': 31490,\n",
       "  'fears': 13703,\n",
       "  'rising': 32943,\n",
       "  'dollar': 11040,\n",
       "  'tom': 39025,\n",
       "  'luongo': 23025,\n",
       "  'reserve': 32469,\n",
       "  'market': 23654,\n",
       "  'committee': 7511,\n",
       "  'choose': 6690,\n",
       "  'raise': 31315,\n",
       "  'interest': 19521,\n",
       "  'rate': 31488,\n",
       "  'statement': 36689,\n",
       "  'ben': 3700,\n",
       "  'carson': 5902,\n",
       "  'slam': 35612,\n",
       "  'reporter': 32368,\n",
       "  'question': 31098,\n",
       "  'cnn': 7162,\n",
       "  'spend': 36308,\n",
       "  'friday': 14811,\n",
       "  'aggressively': 782,\n",
       "  'rebut': 31698,\n",
       "  'medium': 24186,\n",
       "  'report': 32364,\n",
       "  'strike': 37083,\n",
       "  'departure': 9959,\n",
       "  'mellow': 24263,\n",
       "  'personality': 28895,\n",
       "  'display': 10760,\n",
       "  'trail': 39249,\n",
       "  'desperation': 10125,\n",
       "  'behalf': 3589,\n",
       "  'try': 39677,\n",
       "  'tarnish': 38112,\n",
       "  'look': 22788,\n",
       "  'talk': 38002,\n",
       "  'everybody': 12915,\n",
       "  'know': 21358,\n",
       "  'tell': 38331,\n",
       "  'availability': 2737,\n",
       "  'florida': 14309,\n",
       "  'get': 15475,\n",
       "  'scandal': 34004,\n",
       "  'nurse': 26953,\n",
       "  'desperate': 10123,\n",
       "  'week': 42164,\n",
       "  'kindergarten': 21196,\n",
       "  'teacher': 38211,\n",
       "  'pee': 28678,\n",
       "  'pant': 28223,\n",
       "  'ridiculous': 32846,\n",
       "  'ok': 27273,\n",
       "  'totally': 39142,\n",
       "  'personal': 28894,\n",
       "  'narrative': 25962,\n",
       "  'centerpiece': 6197,\n",
       "  'star': 36639,\n",
       "  'power': 29913,\n",
       "  'revolve': 32739,\n",
       "  'account': 306,\n",
       "  'violent': 41559,\n",
       "  'description': 10082,\n",
       "  'heal': 17131,\n",
       "  'publish': 30782,\n",
       "  'thursday': 38808,\n",
       "  'childhood': 6608,\n",
       "  'friend': 14822,\n",
       "  'surprise': 37597,\n",
       "  'incident': 18839,\n",
       "  'describe': 10078,\n",
       "  'book': 4559,\n",
       "  'speech': 36288,\n",
       "  'interview': 19609,\n",
       "  'recollection': 31770,\n",
       "  'event': 12898,\n",
       "  'scott': 34240,\n",
       "  'glover': 15751,\n",
       "  'maeve': 23206,\n",
       "  'reston': 32563,\n",
       "  'speak': 36236,\n",
       "  'classmate': 6962,\n",
       "  'neighbor': 26188,\n",
       "  'grow': 16316,\n",
       "  'memory': 24299,\n",
       "  'anger': 1513,\n",
       "  'violence': 41558,\n",
       "  'candidate': 5655,\n",
       "  'morning': 25355,\n",
       "  'network': 26265,\n",
       "  'bunch': 5266,\n",
       "  'lie': 22392,\n",
       "  'alisyn': 1084,\n",
       "  'camerota': 5602,\n",
       "  'ask': 2318,\n",
       "  'attempt': 2561,\n",
       "  'history': 17638,\n",
       "  'pathetic': 28490,\n",
       "  'basically': 3360,\n",
       "  'distract': 10851,\n",
       "  'argument': 2069,\n",
       "  'launch': 21911,\n",
       "  'aggressive': 781,\n",
       "  'attack': 2551,\n",
       "  'accuse': 327,\n",
       "  'scrutinize': 34315,\n",
       "  'barack': 3204,\n",
       "  'obama': 27014,\n",
       "  'hillary': 17538,\n",
       "  'clinton': 7062,\n",
       "  'degree': 9693,\n",
       "  'vet': 41405,\n",
       "  'close': 7094,\n",
       "  'guy': 16518,\n",
       "  'ago': 803,\n",
       "  'garbage': 15187,\n",
       "  'break': 4860,\n",
       "  'repeatedly': 32334,\n",
       "  'approach': 1913,\n",
       "  'publication': 30774,\n",
       "  'staff': 36558,\n",
       "  'decline': 9527,\n",
       "  'comment': 7484,\n",
       "  'assist': 2405,\n",
       "  'locate': 22687,\n",
       "  'victim': 41450,\n",
       "  'provide': 30664,\n",
       "  'insight': 19336,\n",
       "  'explain': 13166,\n",
       "  'aspect': 2335,\n",
       "  'feel': 13749,\n",
       "  'incorrect': 18899,\n",
       "  'point': 29580,\n",
       "  'challenge': 6318,\n",
       "  'veracity': 41335,\n",
       "  'reflect': 31969,\n",
       "  'youth': 43174,\n",
       "  'night': 26456,\n",
       "  'piece': 29172,\n",
       "  'bold': 4475,\n",
       "  'face': 13338,\n",
       "  'autobiography': 2701,\n",
       "  'explicitly': 13177,\n",
       "  'apply': 1886,\n",
       "  'afterward': 753,\n",
       "  'sgt': 34774,\n",
       "  'hunt': 18201,\n",
       "  'introduce': 19652,\n",
       "  'general': 15339,\n",
       "  'william': 42511,\n",
       "  'westmoreland': 42281,\n",
       "  'dinner': 10482,\n",
       "  'congressional': 7841,\n",
       "  'medal': 24137,\n",
       "  'winner': 42580,\n",
       "  'later': 21872,\n",
       "  'offer': 27206,\n",
       "  'scholarship': 34129,\n",
       "  'west': 42260,\n",
       "  'outright': 27796,\n",
       "  'let': 22253,\n",
       "  'military': 24672,\n",
       "  'career': 5804,\n",
       "  'write': 42880,\n",
       "  'acknowledge': 364,\n",
       "  'times': 38882,\n",
       "  'informal': 19159,\n",
       "  'record': 31799,\n",
       "  'like': 22450,\n",
       "  'easily': 11671,\n",
       "  'armstrong': 2147,\n",
       "  'williams': 42512,\n",
       "  'business': 5369,\n",
       "  'manager': 23432,\n",
       "  'clear': 6991,\n",
       "  'gracefully': 16014,\n",
       "  'medicine': 24175,\n",
       "  'politico': 29649,\n",
       "  'writer': 42881,\n",
       "  'gain': 15093,\n",
       "  'headline': 17112,\n",
       "  'substantiate': 37269,\n",
       "  'article': 2223,\n",
       "  'wolf': 42693,\n",
       "  'blitzer': 4273,\n",
       "  'spokeswoman': 36404,\n",
       "  'theresa': 38624,\n",
       "  'brinkerhoff': 4987,\n",
       "  'interaction': 19494,\n",
       "  'enroll': 12428,\n",
       "  'files': 13977,\n",
       "  'potential': 29885,\n",
       "  'cadet': 5473,\n",
       "  'keep': 20920,\n",
       "  'student': 37137,\n",
       "  'letter': 22260,\n",
       "  'admission': 559,\n",
       "  'adjutant': 531,\n",
       "  'army': 2148,\n",
       "  'common': 7518,\n",
       "  'recruit': 31821,\n",
       "  'well': 42225,\n",
       "  'bright': 4968,\n",
       "  'imagine': 18554,\n",
       "  'lack': 21656,\n",
       "  'tuition': 39722,\n",
       "  'federally': 13732,\n",
       "  'fund': 14970,\n",
       "  'institution': 19396,\n",
       "  'communicate': 7533,\n",
       "  'interpret': 19577,\n",
       "  'odd': 27164,\n",
       "  'pursue': 30913,\n",
       "  'discussion': 10630,\n",
       "  'kind': 21193,\n",
       "  'terminology': 38430,\n",
       "  'old': 27293,\n",
       "  'occur': 27138,\n",
       "  'speaking': 36241,\n",
       "  'gala': 15104,\n",
       "  'black': 4139,\n",
       "  'caucus': 6057,\n",
       "  'palm': 28153,\n",
       "  'beach': 3471,\n",
       "  'gardens': 15200,\n",
       "  'reflective': 31973,\n",
       "  'dirty': 10526,\n",
       "  'world': 42793,\n",
       "  'politic': 29637,\n",
       "  'wonderful': 42714,\n",
       "  'frequently': 14789,\n",
       "  'mention': 24335,\n",
       "  'scrutiny': 34317,\n",
       "  'remainder': 32218,\n",
       "  'briefly': 4961,\n",
       "  'allude': 1151,\n",
       "  'forcefully': 14465,\n",
       "  'soft': 35969,\n",
       "  'quiet': 31120,\n",
       "  'start': 36664,\n",
       "  'loud': 22863,\n",
       "  'particularly': 28393,\n",
       "  'injustice': 19252,\n",
       "  'plans': 29390,\n",
       "  'press': 30181,\n",
       "  'ahead': 835,\n",
       "  'guantanamo': 16367,\n",
       "  'bay': 3443,\n",
       "  'closure': 7105,\n",
       "  'white': 42365,\n",
       "  'emphasize': 12217,\n",
       "  'willingness': 42518,\n",
       "  'executive': 13056,\n",
       "  'action': 406,\n",
       "  'promise': 30504,\n",
       "  'prison': 30326,\n",
       "  'cuba': 8910,\n",
       "  'rhetorical': 32775,\n",
       "  'shift': 35023,\n",
       "  'suggest': 37355,\n",
       "  'recognition': 31764,\n",
       "  'congress': 7839,\n",
       "  'unlikely': 40558,\n",
       "  'step': 36815,\n",
       "  'shutter': 35249,\n",
       "  'facility': 13363,\n",
       "  'investigating': 19706,\n",
       "  'november': 26832,\n",
       "  'good': 15890,\n",
       "  'tuesday': 39718,\n",
       "  'silly': 35366,\n",
       "  'claim': 6906,\n",
       "  'investigate': 19705,\n",
       "  'rogue': 33099,\n",
       "  'email': 12107,\n",
       "  'setup': 34730,\n",
       "  'woman': 42701,\n",
       "  'gem': 15328,\n",
       "  'robin': 33041,\n",
       "  'lakoff': 21715,\n",
       "  'berkeley': 3784,\n",
       "  'professor': 30423,\n",
       "  'sustain': 37660,\n",
       "  'incoherence': 18867,\n",
       "  'special': 36249,\n",
       "  'plead': 29441,\n",
       "  'emailgate': 12108,\n",
       "  'communication': 7535,\n",
       "  'mad': 23166,\n",
       "  'scare': 34027,\n",
       "  'bitch': 4116,\n",
       "  'flap': 14195,\n",
       "  'leg': 22109,\n",
       "  'female': 13799,\n",
       "  'happen': 16834,\n",
       "  'petraeus': 28971,\n",
       "  'thank': 38549,\n",
       "  'nice': 26405,\n",
       "  'guilty': 16425,\n",
       "  'swf': 37754,\n",
       "  'reminder': 32239,\n",
       "  'punish': 30863,\n",
       "  'sake': 33643,\n",
       "  'decent': 9483,\n",
       "  'escalate': 12683,\n",
       "  'quickly': 31114,\n",
       "  'incoherently': 18869,\n",
       "  'pretty': 30224,\n",
       "  'sure': 37568,\n",
       "  'decade': 9456,\n",
       "  'parody': 28358,\n",
       "  'channel': 6359,\n",
       "  'yes': 43093,\n",
       "  'mess': 24407,\n",
       "  'albright': 995,\n",
       "  'rice': 32806,\n",
       "  'similar': 35388,\n",
       "  'male': 23357,\n",
       "  'scold': 34211,\n",
       "  'idea': 18397,\n",
       "  'absurd': 220,\n",
       "  'absolute': 201,\n",
       "  'theory': 38614,\n",
       "  'creationist': 8636,\n",
       "  'emailing': 12110,\n",
       "  'classify': 6958,\n",
       "  'information': 19162,\n",
       "  'server': 34696,\n",
       "  'avoid': 2774,\n",
       "  'transparency': 39339,\n",
       "  'regulation': 32070,\n",
       "  'illegal': 18505,\n",
       "  'rodham': 33074,\n",
       "  'stand': 36608,\n",
       "  'bossy': 4659,\n",
       "  'uppity': 40899,\n",
       "  'ambitious': 1280,\n",
       "  'engage': 12363,\n",
       "  'level': 22278,\n",
       "  'wrong': 42889,\n",
       "  'illegally': 18507,\n",
       "  'lawbreaking': 21949,\n",
       "  'airbnb': 881,\n",
       "  'sends': 34586,\n",
       "  'spam': 36205,\n",
       "  'violates': 41553,\n",
       "  'yves': 43229,\n",
       "  'smith': 35780,\n",
       "  'receive': 31718,\n",
       "  'mail': 23277,\n",
       "  'patently': 28482,\n",
       "  'violate': 41551,\n",
       "  'virtue': 41579,\n",
       "  'have': 17036,\n",
       "  'unsubscribe': 40778,\n",
       "  'option': 27514,\n",
       "  'cheeky': 6488,\n",
       "  'contact': 8006,\n",
       "  'deeply': 9590,\n",
       "  'visit': 41602,\n",
       "  'site': 35498,\n",
       "  'lodger': 22715,\n",
       "  'host': 17990,\n",
       "  'mean': 24098,\n",
       "  'likely': 22455,\n",
       "  'manner': 23503,\n",
       "  'harvest': 16957,\n",
       "  'address': 489,\n",
       "  'problem': 30366,\n",
       "  'party': 28412,\n",
       "  'internet': 19566,\n",
       "  'access': 276,\n",
       "  'services': 34702,\n",
       "  'natural': 26038,\n",
       "  'end': 12298,\n",
       "  'recipient': 31742,\n",
       "  'relevant': 32183,\n",
       "  'provision': 30676,\n",
       "  'wikipedia': 42469,\n",
       "  'basic': 3359,\n",
       "  'type': 39885,\n",
       "  'compliance': 7611,\n",
       "  'define': 9653,\n",
       "  'content': 8043,\n",
       "  'send': 34581,\n",
       "  'behavior': 3596,\n",
       "  'follow': 14407,\n",
       "  'visible': 41598,\n",
       "  'operable': 27442,\n",
       "  'mechanism': 24132,\n",
       "  'present': 30156,\n",
       "  'consumer': 7999,\n",
       "  'opt': 27499,\n",
       "  'request': 32432,\n",
       "  'honor': 17869,\n",
       "  'list': 22574,\n",
       "  'suppression': 37551,\n",
       "  'purpose': 30905,\n",
       "  'accurate': 322,\n",
       "  'friendly': 14825,\n",
       "  'froms': 14861,\n",
       "  'subject': 37214,\n",
       "  'relative': 32162,\n",
       "  'body': 4426,\n",
       "  'deceptive': 9488,\n",
       "  'legitimate': 22142,\n",
       "  'physical': 29123,\n",
       "  'publisher': 30784,\n",
       "  'advertiser': 633,\n",
       "  'po': 29538,\n",
       "  'box': 4730,\n",
       "  'acceptable': 270,\n",
       "  'entity': 12479,\n",
       "  'product': 30402,\n",
       "  'promote': 30510,\n",
       "  'label': 21632,\n",
       "  'adult': 602,\n",
       "  'sending': 34584,\n",
       "  'message': 24408,\n",
       "  'relay': 32169,\n",
       "  'contain': 8014,\n",
       "  'false': 13472,\n",
       "  'header': 17107,\n",
       "  'sentence': 34619,\n",
       "  'null': 26914,\n",
       "  'offend': 27198,\n",
       "  'belonging': 3685,\n",
       "  'means': 24106,\n",
       "  'entirety': 12475,\n",
       "  'commitment': 7507,\n",
       "  'hi': 17470,\n",
       "  'earlier': 11642,\n",
       "  'comprehensive': 7638,\n",
       "  'bias': 3926,\n",
       "  'result': 32579,\n",
       "  'agree': 813,\n",
       "  'agreeing': 815,\n",
       "  'affect': 684,\n",
       "  'want': 41936,\n",
       "  'commit': 7506,\n",
       "  'treat': 39402,\n",
       "  'regardless': 32027,\n",
       "  'race': 31196,\n",
       "  'religion': 32194,\n",
       "  'origin': 27600,\n",
       "  'ethnicity': 12811,\n",
       "  'disability': 10530,\n",
       "  'age': 759,\n",
       "  'respect': 32522,\n",
       "  'judgment': 20543,\n",
       "  'accept': 268,\n",
       "  'log': 22723,\n",
       "  'website': 42147,\n",
       "  'mobile': 25035,\n",
       "  'tablet': 37904,\n",
       "  'app': 1830,\n",
       "  'automatically': 2716,\n",
       "  'will': 42502,\n",
       "  'able': 142,\n",
       "  'cancel': 5639,\n",
       "  'future': 15029,\n",
       "  'trip': 39506,\n",
       "  'browse': 5108,\n",
       "  'reservation': 32468,\n",
       "  'guest': 16400,\n",
       "  'feedback': 13746,\n",
       "  'welcome': 42218,\n",
       "  'nondiscrimination': 26629,\n",
       "  'read': 31582,\n",
       "  'team': 38219,\n",
       "  'sent': 34617,\n",
       "  'ireland': 19798,\n",
       "  'watermarque': 42054,\n",
       "  'building': 5219,\n",
       "  'lotts': 22859,\n",
       "  'rd': 31562,\n",
       "  'ringsend': 32912,\n",
       "  'dublin': 11421,\n",
       "  'vat': 41245,\n",
       "  'number': 26924,\n",
       "  'entry': 12501,\n",
       "  'commentator': 7487,\n",
       "  'analyst': 1419,\n",
       "  'monday': 25186,\n",
       "  'opinion': 27459,\n",
       "  'express': 13215,\n",
       "  'commentary': 7486,\n",
       "  'solely': 35994,\n",
       "  'author': 2684,\n",
       "  'gergen': 15443,\n",
       "  'crush': 8862,\n",
       "  'trump': 39612,\n",
       "  'coming': 7457,\n",
       "  'decisively': 9511,\n",
       "  'virtually': 41578,\n",
       "  'lock': 22692,\n",
       "  'suspect': 37645,\n",
       "  'ferociously': 13833,\n",
       "  'traditional': 39233,\n",
       "  'standard': 36610,\n",
       "  'carefully': 5809,\n",
       "  'marshal': 23706,\n",
       "  'fact': 13368,\n",
       "  'smile': 35773,\n",
       "  'roll': 33114,\n",
       "  'indictment': 18974,\n",
       "  'donald': 11075,\n",
       "  'contrast': 8103,\n",
       "  'unprepared': 40640,\n",
       "  'fresh': 14791,\n",
       "  'increasingly': 18908,\n",
       "  'rant': 31423,\n",
       "  'even': 12895,\n",
       "  'bury': 5352,\n",
       "  'criticism': 8750,\n",
       "  'doubt': 11184,\n",
       "  'away': 2799,\n",
       "  'thing': 38668,\n",
       "  'supporter': 37539,\n",
       "  'judge': 20536,\n",
       "  'hear': 17149,\n",
       "  'establishment': 12754,\n",
       "  'politician': 29641,\n",
       "  'deliver': 9770,\n",
       "  'crave': 8610,\n",
       "  'different': 10392,\n",
       "  'quick': 31111,\n",
       "  'angry': 1528,\n",
       "  'figure': 13961,\n",
       "  'voice': 41683,\n",
       "  'stick': 36867,\n",
       "  'despite': 10130,\n",
       "  'ineffectual': 19055,\n",
       "  'performance': 28802,\n",
       "  'equally': 12576,\n",
       "  'seemingly': 34465,\n",
       "  'struggle': 37121,\n",
       "  'create': 8630,\n",
       "  'bond': 4524,\n",
       "  'voter': 41742,\n",
       "  'vex': 41415,\n",
       "  'issue': 19953,\n",
       "  'likeability': 22451,\n",
       "  'recent': 31723,\n",
       "  'concern': 7686,\n",
       "  'ability': 135,\n",
       "  'mobilize': 25040,\n",
       "  'millennials': 24689,\n",
       "  'successfully': 37300,\n",
       "  'certainly': 6241,\n",
       "  'blow': 4335,\n",
       "  'ultimate': 39964,\n",
       "  'stay': 36735,\n",
       "  'tune': 39750,\n",
       "  'cupp': 8978,\n",
       "  'job': 20387,\n",
       "  'criterium': 8743,\n",
       "  'check': 6474,\n",
       "  'basis': 3367,\n",
       "  'determine': 10192,\n",
       "  'outcome': 27730,\n",
       "  'undecideds': 40184,\n",
       "  'dumb': 11482,\n",
       "  'bully': 5256,\n",
       "  'liar': 22335,\n",
       "  'trust': 39653,\n",
       "  'chance': 6341,\n",
       "  'add': 469,\n",
       "  'unfortunately': 40408,\n",
       "  'cavalier': 6085,\n",
       "  'attitude': 2581,\n",
       "  'nuclear': 26894,\n",
       "  'weapon': 42112,\n",
       "  'dangerous': 9223,\n",
       "  'punt': 30873,\n",
       "  'opportunity': 27480,\n",
       "  'ill': 18504,\n",
       "  'inform': 19158,\n",
       "  'instead': 19384,\n",
       "  'prefer': 30068,\n",
       "  'argue': 2066,\n",
       "  'vague': 41106,\n",
       "  'platform': 29407,\n",
       "  'merit': 24375,\n",
       "  'needle': 26151,\n",
       "  'hammer': 16737,\n",
       "  'home': 17792,\n",
       "  'touch': 39149,\n",
       "  'character': 6378,\n",
       "  'outmanned': 27774,\n",
       "  'specific': 36263,\n",
       "  'detail': 10164,\n",
       "  'far': 13525,\n",
       "  'effective': 11836,\n",
       "  'checker': 6477,\n",
       "  'busy': 5384,\n",
       "  'mislead': 24906,\n",
       "  'move': 25489,\n",
       "  'tonight': 39058,\n",
       "  'robby': 33030,\n",
       "  'mook': 25302,\n",
       "  'assure': 2425,\n",
       "  'anti': 1661,\n",
       "  'grade': 16022,\n",
       "  'curve': 9026,\n",
       "  'homework': 17827,\n",
       "  'prep': 30110,\n",
       "  'pay': 28585,\n",
       "  'especially': 12722,\n",
       "  'important': 18699,\n",
       "  'terrible': 38448,\n",
       "  'hide': 17486,\n",
       "  'tax': 38171,\n",
       "  'return': 32654,\n",
       "  'turn': 39788,\n",
       "  'table': 37897,\n",
       "  'allegation': 1103,\n",
       "  'delete': 9736,\n",
       "  'deserve': 10095,\n",
       "  'take': 37967,\n",
       "  'income': 18870,\n",
       "  'certain': 6240,\n",
       "  'strategy': 37031,\n",
       "  'design': 10100,\n",
       "  'chip': 6645,\n",
       "  'blue': 4348,\n",
       "  'collar': 7316,\n",
       "  'demographic': 9846,\n",
       "  'cultivate': 8951,\n",
       "  'populist': 29766,\n",
       "  'stiffed': 36873,\n",
       "  'foot': 14441,\n",
       "  'mouth': 25482,\n",
       "  'butt': 5394,\n",
       "  'smart': 35747,\n",
       "  'tough': 39156,\n",
       "  'answer': 1621,\n",
       "  'pain': 28090,\n",
       "  'restrain': 32568,\n",
       "  'hate': 17001,\n",
       "  'help': 17299,\n",
       "  'intellectual': 19461,\n",
       "  'average': 2754,\n",
       "  'adviser': 640,\n",
       "  'cost': 8379,\n",
       "  'rebuttal': 31699,\n",
       "  'incoherent': 18868,\n",
       "  'chuckle': 6760,\n",
       "  'viewer': 41485,\n",
       "  ...}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8R4IVhILCEgG"
   },
   "source": [
    "2. Defina la función `evalua_sklearn`  que reciba como argumentos:\n",
    "    - `y_true`: np.array de una dimensión, conteniendo las etiquetas de cada una de las observaciones \n",
    "    - `y_pred`: np.array, con las etiquetas predichas por algún modelo de clasificación\n",
    "    - `nombre_clasificador`: str, define el nombre de la carpeta donde los resultados son guardados. \n",
    "    \n",
    "  Esta función debe:\n",
    "    - Imprimir en pantalla los resultados de clasificación, mediante `sklearn.metrics.classification_report` con 4 dígitos de precisión. Además debe guardar dichos resultadoes  en la ruta `f'resultados/{nombre_clasificador}/reporte_clasificacion.txt'`.\n",
    "    - Generar un gráfico con la *matriz de confusión* mediante el uso de `sklearn.metrics.confusion_matrix` y `seaborn.heatmap`. Además debe guardar dicho gráfico en la ruta `f'resultados/{nombre_clasificador}/mc.pdf'`.\n",
    "    \n",
    "  Pruebe esta función con la predicción de `nb_pipe` sobre el conjunto de *prueba*, usando `nombre_clasificador='nb_pipe'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opHsYtdSEH6J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQ1wjJUqCEgM"
   },
   "source": [
    "- Compruebe que obtiene un *accuracy* y un promedio ponderado de *f1-score* superiores a .89.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F29MRA-xCEgN"
   },
   "source": [
    "#### Representación Tf-idf\n",
    "\n",
    "Para esta sección y la posterior se emplea la clase `sklearn.feature_extraction.text.TfidfVectorizer`. \n",
    "\n",
    "Para comprender el algoritmo ***tf-idf*** (*term frequency - inverse document frequency*) necesitamos definir 3 de sus componentes:\n",
    "- $\\text{tf}(t_j, \\mathbf{d}_i)$ que representa el número de apariciones del *token* $t_j$ en el *documento* $\\mathbf{d}_i$.\n",
    "\n",
    "- $\\text{df}(t_j)$ que representa el número de documentos en que aparece el *token* $t_j$.\n",
    "- $\\text{idf}(t_j)$ que representa el inverso de la frecuencia del *token* $t_j$ en los *documentos* del *corpus*. En el caso particular del objeto `~.TfidfVectorizer` empleado, denotando por $n$ al numero de documentos del *corpus*, se usa una versión suavizada de la función $\\text{idf}$. Esto es: \n",
    "\n",
    "$$\n",
    "\\text{idf}(t_j) = \\log(\\frac{1 + n}{1 + \\text{df}(t_j)}) + 1\n",
    "$$\n",
    "\n",
    "\n",
    "Con dichos componentes, podemos definir a la representación vectorial del documento $\\mathbf{d}_i$ mediante el vector $\\textbf{tf-idf}(\\mathbf{d}_i)$, cuyas coordenadas se calculan de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\left(\\textbf{tf-idf}(\\mathbf{d}_i)_i\\right) = \\text{tf}(t_j, \\mathbf{d}_i) \\times \\text{idf}(t_j)\n",
    "$$\n",
    "\n",
    "\n",
    "Así la salida del objeto `~.TfidfVectorizer` es la matriz de la concatenación por filas, de los vectores $\\textbf{tf-idf}(\\mathbf{d}_i)$ normalizados según la norma euclidiana, es decir, la matriz $\\mathbf{X}$, definida por:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left( x_{i,j} \\right) = \\frac{\\text{tf}(t_j, \\mathbf{d}_i) \\times \\text{idf}(t_j)}{{||\\textbf{tf-idf}(\\mathbf{d}_i)||}_2} \n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "donde ${||\\cdot||}_2$ representa la norma euclidiana. En consecuencia se logra una representación vectorial sobre la esfera unitaria de la norma ${||\\cdot||}_2$.\n",
    "\n",
    "Una interpretación posible de esta representación vectorial es que cada *token* $t_j$ tiene mayor importancia en el documento $\\mathbf{d}_i$:\n",
    "\n",
    "- En la medida en que esta aparezca más veces en el documento\n",
    "- En la medida en que esta aparezca menos veces en los demás documentos del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8A8IZPoCEgN"
   },
   "source": [
    "#### Maquinas de soporte vectorial (SVM)\n",
    "\n",
    "Se emplea el algoritmo de máquinas de soporte vectorial (*Support Vector Machines - SVM*) sobre la representación vectorial *tf-idf*. La clase utilizada para generar este modelo es `sklearn.svm.SVC`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_rQh6ZPE4dA"
   },
   "source": [
    "##### Pregunta 3\n",
    "1. Instancie `svm_pipe` como un objeto de la clase `sklearn.pipeline.Pipeline` con los componentes:\n",
    "    - `~.TfidfVectorizer` inicializado con `max_features=20000` los demás parámetros por defecto.\n",
    "    - `~.SVC` inicializado con el kernel RBF y los parámetros por defecto.  \n",
    "    \n",
    "   Posteriormente, ajuste `svm_pipe` en el conjunto de *entrenamiento union validación* y guarde el modelo resultante en la carpeta `modelos/svm_pipe.pk` como un archivo `pickle`. Finalmente, reporte el desempeño del clasificador mediante `evalua_sklearn` con la predicción de `svm_pipe` sobre el conjunto de *prueba*, usando `nombre_clasificador='svm_pipe'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-fRguPeELN-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xj3HbM47CEgT"
   },
   "source": [
    "Las máquinas de soporte vectorial son algoritmos que pueden ser muy sensibles a los hiperparámetros. Por esta razón es útil emplear un esquema de validación cruzada. A continuación se implementa un esquema de validación cruzada simple, que explora sólo diferentes kernels y coeficientes de regularización.\n",
    "2. Instancie `svm_grid` como un objeto de la clase `sklearn.model_selection.GridSearchCV`con los parámetros:\n",
    "    - `n_jobs=-1` para usar todos los núcleos disponibles\n",
    "    - `param_grid` definido de tal forma que le permita probar las combinaciones de los siguientes hiperparámetros de `~SVC`:\n",
    "        - `kernel` en {`'lineal'`, `'rbf'`}\n",
    "        - `C` en {`.01`, `.1`, `1`, `10`, `100`}\n",
    "\n",
    "    - `cv=3` para generar un esquema de validación cruzada estratificada con 3 *fold*.\n",
    "    - `verbose=1` para reportar el progreso del ajuste en pantalla\n",
    "    \n",
    "  Los demás parámetros quedan con sus valores por defecto.  \n",
    "  \n",
    "  Ajuste `grid_search_svm` usando `svm_pipe` sobre el conjunto *entrenamiento union validación* y guarde el modelo resultante en la carpeta `modelos/svm_grid.pk` como un archivo `pickle`. Luego reporte el desempeño del clasificador mediante `evalua_sklearn` con la predicción de `svm_grid` sobre el conjunto de *prueba*, usando `nombre_clasificador='svm_grid'`.  \n",
    "  \n",
    "  **Obs**: Evite fuga de información al combinar ``svm_pipe`` con `grid_search_svm`.\n",
    "\n",
    "  Finalmente, en ruta `resultados/svm_grid/mejores_parametros.txt` guarde los mejores parámetros obtenidos en `svm_grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJJyKChuEOLr"
   },
   "outputs": [],
   "source": [
    "# no olvide fijar la semilla \n",
    "np.random.seed(seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CW8MfC6GEdgD"
   },
   "source": [
    "### Modelos paramétricos\n",
    "\n",
    "En lo que sigue del ejercicio se construirá una red neuronal recurrente (*RNN*). Para ello se usará principalmente la librería `torchtext` que provee una serie de herramientas que facilitan el manejo de texto para redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqXRozFCFCYS"
   },
   "source": [
    "#### Representación vectorial densa\n",
    "\n",
    "En las representaciones vectoriales anteriores, cada *token* del *vocabulario* constituye una dimension del espacio, es decir, hay tantas dimensiones en el espacio vectorial de representación como *tokens* en el *vocabulario*.\n",
    "\n",
    "Hay una desventaja enorme en esta representación, además de la cantidad enorme de dimensiones que genera. Esta es que básicamente trata todos los *token* como entidades independientes sin relación entre sí. Lo que se busca en una representación densa es alguna noción de similitud entre las palabras.\n",
    "\n",
    "Por ejemplo, supoga que se construye un modelo de lenguaje y que hemos visto las oraciones:\n",
    "\n",
    "- El matemático corrió a la tienda.\n",
    "- El físico corrió a la tienda.\n",
    "- El matemático resolvió un problema abierto.\n",
    "\n",
    "en el conjunto de *entrenamiento*. Ahora supongamos que obtenemos una nueva oración no presente en el conjunto de *entrenamiento*:\n",
    "\n",
    "- El físico resolvió un problema abierto.\n",
    "\n",
    "Si bien el modelo de lenguaje puede funcionar bien en esta oración, sería mejor si se pudiera utilizar los siguientes aspectos:\n",
    "\n",
    "- Se ha observado matemático y físico en el mismo papel en una oración. De alguna manera tienen una relación semántica.\n",
    "- Se ha observado al matemático en el rol del físico en una oración análoga a esta nueva oración.\n",
    "\n",
    "Así, se podría inferir que el físico en realidad encaja bien en la nueva oración. Esto esconde una noción de similitud: queremos decir similitud semántica, no simplemente tener representaciones ortográficas similares. Este ejemplo, por supuesto, se basa en una suposición lingüística fundamental: que las palabras que aparecen en contextos similares están relacionadas semánticamente entre sí. Esto se llama hipótesis ***distribucional***.\n",
    "\n",
    "Sobre dicha hipotesis se basa la construcción de modelos de procesamiento de lenguaje natural llamado ***word embeddings*** que se utilizan a continuación.\n",
    "\n",
    "<center>Explicación adaptada de <a href=\"https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html\">Word Embedding: Encoding Lexical Semantics - Pytorch</a></center> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRUh3opLLJ3P"
   },
   "source": [
    "##### Pregunta 4 \n",
    "La forma de cargar datos en formato csv que provee `torchtext`, es mediante los objetos `torchtext.data.dataset.TabularDataset`. A direfencia de `pandas.read_csv`, donde la función puede inferir el tipo de dato de cada columna, `~.TabularDataset` necesita que dichos tipos de dato sean declarados, mediante el objeto `torchtext.data.Field`.\n",
    "\n",
    "1. Instancie `train_td`, `val_td` y `test_td` mediante el método `~.TabularDataset.splits` que le permita cargar textos de los archivos `conjuntos/*.csv` respectivos. Para ello tendrá que instanciar dos objetos de la clase `~.Field` que definan el tipo de dato para cada columna:\n",
    "\n",
    "- La columna `y`: declarada mediante el objeto `etiqueta_fd` como instancia de `~.Field`, con parametros `sequential=False, use_vocab=False, batch_first=True, dtype=torch.float` y los demás por defecto.\n",
    "- La columna `pro_X`:  declarada mediante el objeto `documento_fd`, como instancia de `~.Field`, con parámetros `include_lengths=True, batch_first=True` y los demás por defecto. El primer parámetro (`include_lengths=True`) implica que cada *documento* cargado de la columna se entregará en forma de tupla, donde además de la secuencia de *tokens* de aquel *documento*, se adjuntará el largo de la secuencia o número de tokens contenidos en este.\n",
    "\n",
    "**Obs**: Tendrá que inferir los parámetros con los cuales emplear el método `~.splits()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CPFslHMO7OF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ZQsjBrESIYZ"
   },
   "source": [
    "`torchtext` también provee objetos que permiten iterar sobre un objeto de tipo `~.TabularDataset`. En particular, en el procesamiento de texto es beneficioso generar *batches* de secuencias que tengan largo similar, para ahorrar tiempo de escritura, ya que dichos *batches* al tener forma tensorial, deben ser completados por ceros (*padding*). Así por ejemplo, las secuencias:\n",
    "```\n",
    "[ [4, 16, 3, 8],\n",
    "  [5, 2],\n",
    "  [6, 6, 7, 9, 2] ]\n",
    "```\n",
    "deben ser transformadas a:\n",
    "```\n",
    "[ [4, 16, 3, 8, 0],\n",
    "  [5, 2, 0, 0, 0],\n",
    "  [6, 6, 7, 8, 2] ]\n",
    "```\n",
    "\n",
    "Mediante la clase ` torchtext.data.BucketIterator`, es posible iterar sobre instancias de `~.TabularDataset`, de manera que se minimiza la cantidad de *padding* y al mismo tiempo se mantiene un orden aleatorio de los datos.\n",
    "\n",
    "2.  Instancie *iterators* de cada uno de los `~.TabularDataset` instanciados, mediante `~.BucketIterator.splits` con los parámetros `batch_size=32, sort_key=lambda x: len(x.pro_X),\n",
    "device=device, sort=True, sort_within_batch=True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvPAvN1eUX9E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PI4uDB6mUWd2"
   },
   "source": [
    "3. Obtenga la representación vectorial del vocabulario con el *word embedding* GloVe entrenado en [Wikipedia 2014 + GigaWord 5](https://nlp.stanford.edu/projects/glove/). Para ello:\n",
    "- Instancie el objeto `glove` como una instancia de la clase `torchtext.vocab.GloVe` con los parámetros`name=\"6B\", dim=300`.\n",
    "- Ejecute el método `build_vocab` del objeto `documento_fd` con `max_size=20000` y los demás parámetros que correspondan   \n",
    "  Compruebe posteiormente que al llamar a `documento_fd.vocab.vectors.shape` obtiene las dimensiones `(20002,300)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5l65cImC6in6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iQ875UiZYrY4"
   },
   "source": [
    "#### LSTM \n",
    "Finalmete se implementa una LSTM bidireccional. La estructura de la red LSTM ya fue revisada en el material del curso, sin embargo, no se estudió su variante bidireccional. Esta denominación implica que la secuencia de tokens presente en cada texto es procesada desde el primer token hasta el último en una LSTM y desde el úĺtimo hasta el primero en otra LSTM, tal como lo ilustra la siguiente imagen.\n",
    "\n",
    "<center> <img src=\"http://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-bidirectional.png\" align=\"middle\"> </center>\n",
    "<center> Fuente: <a href=\"http://colah.github.io/posts/2015-09-NN-Types-FP/\"> Colah's Blog </a></center>\n",
    "\n",
    "Por consistencia con la imagen, supongamos que la LSTM bidireccional recibe un documento compuesto por la secuencia de tokens $x_0, \\ldots, x_u$, de largo $i+1$. Sean $\\text{LSTM}$ la RNN que recibe los inputs desde $0$ hasta $i$ y $\\text{LSTM}'$ la RNN que los recibe desde $i$ hasta $0$. A cada input de la secuencia, $x_j$, corresponde un *output*, $y_j$ que consiste en la concatenación $\\left(A(S_j, x_j),A'(S'_{i-j}, x_j)\\right)$. Lo que debe ser considerado como la salida final de la LSTM bidireccional es la primera mitad de $y_i$ y la segunda mitad de $y_0$ pues corresponden a $A(S_i, x_i)$ y $A'(S'_i, x_0)$ respectivamente. Observe que este es output se asocia a la secuencia completa.\n",
    "\n",
    "La LSTM bi-direccional que se implementa está diseñada para usar un *word embedding* fijo, como el que fue calculado en la sección anterior.\n",
    "\n",
    "La estructura de la red es la siguiente:\n",
    "- *Word embedding* pre-entrenado (no deben calcularse gradientes en esta sección de la red), implementado con la clase `torch.nn.Embedding`.\n",
    "- LSTM bidireccional, tomando como salida la concatenación recién explicada e implementada con la clase `torch.nn.LSTM` con los parámetros `batch_first=True` y `bidirectional=True`. \n",
    "- Dropout con probabilidad .5\n",
    "- Capa totalmente conectada con salida de tamaño 1 y función de activación sigmoide.\n",
    "\n",
    "Dado que `~.BucketIterator` entrega un tensor con *paddings* de cero, es necesario transformar el input de `~.LSTM`, de tal forma que esta no procese los ceros del tensor de entrada. Por esta razón al pasar del output de `~.Embedding`, al input de `~.LSTM`, es necesario emplear la función `torch.nn.utils.rnn.pack_padded_sequence` que permite transformar una secuencia con *paddings* de 0, en una secuencia que los oculta. Dicha función es capaz de transformar un input de la forma:\n",
    "```\n",
    "seq = torch.tensor([[4,5,6], [1,2,0], [3,0,0]])\n",
    "lens = [3, 2, 1]\n",
    "packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=True)\n",
    "```\n",
    "donde el objeto `packed` tendrá la forma:\n",
    "```\n",
    "PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
    "```\n",
    "y estará listo para ser procesado como entrada de `~.LSTM`.\n",
    "\n",
    "Sin embargo, el empleo de aquella función, obliga a usar su función inversa, `torch.nn.utils.rnn.pad_packed_sequence`, sobre la salida de `~.LSTM` y así que pasar de un objeto `PackedSequence` a su formato tensorial con *padding* de 0. En consecuencia al emplear:\n",
    "```\n",
    "lstm = nn.LSTM(...)\n",
    "packed_output, _ = lstm(packed)\n",
    "seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)\n",
    "``` \n",
    "Esto permitirá encontrar el output de la LSTM bidireccional en el tensor `seq_unpacked` de tamaño $B \\times T \\times C$, donde $B$ representa el tamaño del *batch*, $T$ el largo de la secuencia más larga del *batch* y $C$ el tamaño de la dimension del espacio de carácteristicas de la salida de `~.LSTM`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0r7-VImYqgc"
   },
   "source": [
    "##### Pregunta 5\n",
    "\n",
    "1. Defina la clase `Glove6B300BiLSTM` heredando de `torch.nn.Module` y definiendo los métodos:\n",
    "- `__init__`: recibe como parametros `hidden_size`, que regula el parámetro homónimo de `torch.nn.LSTM`; y `text_field` que apunta al `torchtext.data.Field` que ya contiene la representación vectorial densa del *vocabulario* que es utilizado en la capa del *word embedding*.  \n",
    "- `forward`: recibe como argumentos `text` y `text_len` que corresponden a los objetos que entrega `BucketIterator`.  \n",
    "Haga uso de las funciones `~.pack_padded_sequence` con parámetros `batch_first=True, enforce_sorted=True` y `~.pad_packed_sequence`, con parámetro `batch_first=True`. Sea ciudadoso en la selección de los segmentos del tensor de salida de `~.pad_packed_sequence` que deben ser considerados para las capas posteriores.   \n",
    "\n",
    "*Hint*: note que para construir el output de la $\\text{LSTM}$ bidireccional, deberá seleccionar segmentos de un vector de salida y concatenarlos de manera conveniente. Para ello le será de ayuda la variable `text_len`.\n",
    "\n",
    "  \n",
    "Instancie `modelo` como objeto de la clase `Glove6B300BiLSTM` con `hidden_size=128` y `text_field=documento_fd`. Recuerde instanciarlo en el espacio de memoria adecuado mediante el método `to(device)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXgixLg3f_Pc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMfKHOKtgMdJ"
   },
   "source": [
    "2. Implemente el ciclo de entrenamiento de la red `Glove6B300BiLSTM`. Para ello use:\n",
    "- Entropía cruzada binaria como funcion de costo - `torch.nn.BCELoss()`\n",
    "- Adam cómo algoritmo de optimización, con `lr=2e-4`\n",
    "- 10 epocas de entrenamiento\n",
    "- Los `BucketIterator` definidos en la pregunta anterior para recorrer los conjuntos de entrenamiento y validación.\n",
    "- Guarde en una lista el historico de valores de la función de costo en el conjunto de entrenamiento y de validación\n",
    "- Al final de cada época guarde el modelo mediante `guardar_modelo` en la ruta `modelos/Glove6B300BiLSTM.h5`, si es que la función de costo sobre el conjunto de validación es menor que la menor función de costo sobre el conjunto de validación observada en épocas anteriores. \n",
    "\n",
    "Al finalizar el entrenamiento, muestre en pantalla un gráfico con el historico de la función de costo en el conjunto de entrenamiento y en el de validación y guardelo en `resultados/Glove6B300BiLSTM/costo_historico.pdf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvYtjhfcgM69"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7m7lmgRqeUj"
   },
   "source": [
    "3. Obtenga la predicción de `modelo` sobre el conjunto de prueba y reporte el desempeño del clasificador mediante `evalua_sklearn` con la predicción de `modelo` sobre el conjunto de *prueba*, usando `nombre_clasificador='Glove6B300BiLSTM'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNp0XVDeqdq2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de Ejercicio 3 - v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358.367px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "078b2fa807ec46e58d906a68b9276e33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ab4e52784094972a9a2eaac29459c58": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4b27412f255843bb9560597505968c6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc85519c59374446b63168fd61028183",
       "IPY_MODEL_ea81a5d515b64fda92d82e0ecff58d48"
      ],
      "layout": "IPY_MODEL_4ba4377c4d084df0bcf7b4b589e04746"
     }
    },
    "4ba4377c4d084df0bcf7b4b589e04746": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7241d9cf4ba349198cba3b5c90bd47ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc85519c59374446b63168fd61028183": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_078b2fa807ec46e58d906a68b9276e33",
      "max": 6335,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ab4e52784094972a9a2eaac29459c58",
      "value": 6335
     }
    },
    "ea81a5d515b64fda92d82e0ecff58d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8980260172a4afc85dd63e65309e820",
      "placeholder": "​",
      "style": "IPY_MODEL_7241d9cf4ba349198cba3b5c90bd47ff",
      "value": " 6335/6335 [06:25&lt;00:00, 16.44it/s]"
     }
    },
    "f8980260172a4afc85dd63e65309e820": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
